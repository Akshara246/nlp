{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "6bf1a37d-f36e-4d8d-906f-85b77e2a5273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag, ne_chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1e2f7d5c-dd65-462e-8d8f-4f11fd01df65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nirma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nirma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\nirma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nirma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\nirma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\nirma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "64f5ea2d-6ec0-44dd-8243-13a12579742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1335a1fe-6a02-45e7-88d5-7700f7461feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'final'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"finally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "100afcb5-2bfc-4399-a4c4-47a32abdbee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "154df392-fa4b-418d-a3b3-14ea16a20518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finally'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"finally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "038bde87-437b-4f61-960d-9e1f2e7a3e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"FOOD IS GOOD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "302b3ac1-20a7-499b-8bf3-d64b4fa01f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_text(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "33aacbee-bdbb-42d9-aba7-9889574f583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "     return re.sub(r'[^\\w\\s]','', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9126f88f-607d-4512-b0b4-61a73a7d390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3950ab49-0a6a-4593-85fd-e193b69c840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    return[word for word in tokens if word not in stop_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1a282e4a-289f-49b3-a1be-98293e067207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_words(tokens):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "8dd11e4a-21a0-4845-845e-76bd88034bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "02b84ceb-239f-4796-8825-307d670b6a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagging(tokens):\n",
    "    return pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6b382212-bb8d-41bb-919f-6bc5422f7d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def named_entity_recognition(text):\n",
    "    tokens = tokenize_text(text)\n",
    "    pos_tags = pos_tagging(tokens)\n",
    "    return ne_chunk(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e39ea0e5-f9fd-4035-be56-b8f26be7f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lower = lowercase_text(text)\n",
    "text_clean = remove_punctuation(text_lower)\n",
    "tokens = tokenize_text(text_clean)\n",
    "tokens_no_stopwords = remove_stopwords(tokens)\n",
    "tokens_stemmed = stem_words(tokens_no_stopwords)\n",
    "tokens_lemmatized = lemmatize_words(tokens_no_stopwords)\n",
    "pos_tags = pos_tagging(tokens_no_stopwords)\n",
    "named_entities = named_entity_recognition(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a4942d47-86ca-4eee-b4fd-d6eea6a0716e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowercased Text: food is good\n",
      "Cleaned Text: food is good\n",
      "Tokens: ['food', 'is', 'good']\n",
      "Tokens without Stopwords: ['food', 'good']\n",
      "Stemmed Tokens: ['food', 'good']\n",
      "Lemmatized Tokens: ['food', 'good']\n",
      "Part-of-Speech Tags: [('food', 'NN'), ('good', 'NN')]\n",
      "Named Entities: (S (ORGANIZATION FOOD/NNP) IS/NNP GOOD/NNP)\n"
     ]
    }
   ],
   "source": [
    "print(\"Lowercased Text:\", text_lower)\n",
    "print(\"Cleaned Text:\", text_clean)\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"Tokens without Stopwords:\", tokens_no_stopwords)\n",
    "print(\"Stemmed Tokens:\", tokens_stemmed)\n",
    "print(\"Lemmatized Tokens:\", tokens_lemmatized)\n",
    "print(\"Part-of-Speech Tags:\" , pos_tags)\n",
    "print(\"Named Entities:\", named_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222c679d-a602-4716-a699-a0a02e12e18e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
